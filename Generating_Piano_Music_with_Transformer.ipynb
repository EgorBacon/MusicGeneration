{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-RWsbrhmPpP"
   },
   "source": [
    "##### Copyright 2019 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI5g-x4foZls"
   },
   "source": [
    "# Generating Piano Music with Transformer\n",
    "### ___Ian Simon, Anna Huang, Jesse Engel, Curtis \"Fjord\" Hawthorne___\n",
    "\n",
    "This Colab notebook lets you play with pretrained [Transformer](https://arxiv.org/abs/1706.03762) models for piano music generation, based on the [Music Transformer](http://g.co/magenta/music-transformer) model introduced by [Huang et al.](https://arxiv.org/abs/1809.04281) in 2018.\n",
    "\n",
    "The models used here were trained on over 10,000 hours of piano recordings from YouTube, transcribed using [Onsets and Frames](http://g.co/magenta/onsets-frames) and represented using the event vocabulary from [Performance RNN](http://g.co/magenta/performance-rnn).\n",
    "\n",
    "Unlike the original Music Transformer paper, this notebook uses attention based on absolute instead of relative position; we may add models that use relative attention at some point in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDMQbHPYVKmV"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tciXVi5eWG_1"
   },
   "outputs": [],
   "source": [
    "#@title Setup Environment\n",
    "#@markdown Copy some auxiliary data from Google Cloud Storage.\n",
    "#@markdown Also install and import Python dependencies needed\n",
    "#@markdown for running the Transformer models.\n",
    "\n",
    "# %tensorflow_version 1.x\n",
    "\n",
    "print('Copying Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')\n",
    "!gsutil -q -m cp -r 'gs://magentadata/models/music_transformer/primers/*' content/\n",
    "!gsutil -q -m cp 'gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2' content/\n",
    "\n",
    "print('Installing dependencies...')\n",
    "!brew install fluid-synth\n",
    "#libasound2-dev libjack-dev\n",
    "!pip install -q 'tensorflow-datasets < 4.0.0'\n",
    "!pip install -qU google-cloud magenta pyfluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tciXVi5eWG_1"
   },
   "outputs": [],
   "source": [
    "print('Importing libraries...')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.utils import decoding\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "\n",
    "from magenta.models.score2perf import score2perf\n",
    "import note_seq\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3URxzTQyXfdO"
   },
   "outputs": [],
   "source": [
    "#@title Definitions\n",
    "#@markdown Define a few constants and helper functions.\n",
    "\n",
    "SF2_PATH = './content/Yamaha-C5-Salamander-JNv5.1.sf2'\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# Upload a MIDI file and convert to NoteSequence.\n",
    "def upload_midi():\n",
    "  data = list(files.upload().values())\n",
    "  if len(data) > 1:\n",
    "    print('Multiple files uploaded; using only one.')\n",
    "  return note_seq.midi_to_note_sequence(data[0])\n",
    "\n",
    "# Decode a list of IDs.\n",
    "def decode(ids, encoder):\n",
    "  ids = list(ids)\n",
    "  if text_encoder.EOS_ID in ids:\n",
    "    ids = ids[:ids.index(text_encoder.EOS_ID)]\n",
    "  return encoder.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl3oY0w8gBJh"
   },
   "source": [
    "# Piano Performance Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "PBngSJvP_En7"
   },
   "outputs": [],
   "source": [
    "#@title Setup and Load Checkpoint\n",
    "#@markdown Set up generation from an unconditional Transformer\n",
    "#@markdown model.\n",
    "\n",
    "model_name = 'transformer'\n",
    "hparams_set = 'transformer_tpu'\n",
    "# ckpt_path = 'gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt'\n",
    "ckpt_path = './content/unconditional_model_16.ckpt'\n",
    "\n",
    "class PianoPerformanceLanguageModelProblem(score2perf.Score2PerfProblem):\n",
    "  @property\n",
    "  def add_eos_symbol(self):\n",
    "    return True\n",
    "\n",
    "problem = PianoPerformanceLanguageModelProblem()\n",
    "unconditional_encoders = problem.get_feature_encoders()\n",
    "\n",
    "# Set up HParams.\n",
    "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
    "trainer_lib.add_problem_hparams(hparams, problem)\n",
    "hparams.num_hidden_layers = 16\n",
    "hparams.sampling_method = 'random'\n",
    "\n",
    "# Set up decoding HParams.\n",
    "decode_hparams = decoding.decode_hparams()\n",
    "decode_hparams.alpha = 0.0\n",
    "decode_hparams.beam_size = 1\n",
    "\n",
    "# Create Estimator.\n",
    "run_config = trainer_lib.create_run_config(hparams)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    model_name, hparams, run_config,\n",
    "    decode_hparams=decode_hparams)\n",
    "\n",
    "# Create input generator (so we can adjust priming and\n",
    "# decode length on the fly).\n",
    "def input_generator():\n",
    "  global targets\n",
    "  global decode_length\n",
    "  while True:\n",
    "    yield {\n",
    "        'targets': np.array([targets], dtype=np.int32),\n",
    "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
    "    }\n",
    "\n",
    "# These values will be changed by subsequent cells.\n",
    "targets = []\n",
    "decode_length = 0\n",
    "\n",
    "# Start the Estimator, loading from the specified checkpoint.\n",
    "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
    "unconditional_samples = estimator.predict(\n",
    "    input_fn, checkpoint_path=ckpt_path)\n",
    "\n",
    "# \"Burn\" one.\n",
    "_ = next(unconditional_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(unconditional_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_1ybYgKSgIt-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Generate from Scratch\n",
    "#@markdown Generate a piano performance from scratch.\n",
    "#@markdown\n",
    "#@markdown This can take a minute or so depending on the length\n",
    "#@markdown of the performance the model ends up generating.\n",
    "#@markdown Because we use a \n",
    "#@markdown [representation](http://g.co/magenta/performance-rnn)\n",
    "#@markdown where each event corresponds to a variable amount of\n",
    "#@markdown time, the actual number of seconds generated may vary.\n",
    "\n",
    "targets = []\n",
    "decode_length = 1024\n",
    "\n",
    "# Generate sample events.\n",
    "sample_ids = next(unconditional_samples)['outputs']\n",
    "\n",
    "# Decode to NoteSequence.\n",
    "midi_filename = decode(\n",
    "    sample_ids,\n",
    "    encoder=unconditional_encoders['targets'])\n",
    "unconditional_ns = note_seq.midi_file_to_note_sequence(midi_filename)\n",
    "\n",
    "# Play and plot.\n",
    "note_seq.play_sequence(\n",
    "    unconditional_ns,\n",
    "    synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
    "note_seq.plot_sequence(unconditional_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1R7s3MmldBBB"
   },
   "outputs": [],
   "source": [
    "#@title Download Performance as MIDI\n",
    "#@markdown Download generated performance as MIDI (optional).\n",
    "\n",
    "note_seq.sequence_proto_to_midi_file(\n",
    "    unconditional_ns, '/tmp/unconditional.mid')\n",
    "files.download('/tmp/unconditional.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "in5GRrDqKj-f"
   },
   "outputs": [],
   "source": [
    "#@title Choose Priming Sequence\n",
    "#@markdown Here you can choose a priming sequence to be continued\n",
    "#@markdown by the model.  We have provided a few, or you can\n",
    "#@markdown upload your own MIDI file.\n",
    "#@markdown\n",
    "#@markdown Set `max_primer_seconds` below to trim the primer to a\n",
    "#@markdown fixed number of seconds (this will have no effect if\n",
    "#@markdown the primer is already shorter than `max_primer_seconds`).\n",
    "\n",
    "filenames = {\n",
    "    'C major arpeggio': './content/c_major_arpeggio.mid',\n",
    "    'C major scale': './content/c_major_scale.mid',\n",
    "    'Clair de Lune': './content/clair_de_lune.mid',\n",
    "}\n",
    "primer = 'Clair de Lune'  #@param ['C major arpeggio', 'C major scale', 'Clair de Lune', 'Upload your own!']\n",
    "\n",
    "if primer == 'Upload your own!':\n",
    "  primer_ns = upload_midi()\n",
    "else:\n",
    "  # Use one of the provided primers.\n",
    "  primer_ns = note_seq.midi_file_to_note_sequence(filenames[primer])\n",
    "\n",
    "# Handle sustain pedal in the primer.\n",
    "primer_ns = note_seq.apply_sustain_control_changes(primer_ns)\n",
    "\n",
    "# Trim to desired number of seconds.\n",
    "max_primer_seconds = 20  #@param {type:\"slider\", min:1, max:120}\n",
    "if primer_ns.total_time > max_primer_seconds:\n",
    "  print('Primer is longer than %d seconds, truncating.' % max_primer_seconds)\n",
    "  primer_ns = note_seq.extract_subsequence(\n",
    "      primer_ns, 0, max_primer_seconds)\n",
    "\n",
    "# Remove drums from primer if present.\n",
    "if any(note.is_drum for note in primer_ns.notes):\n",
    "  print('Primer contains drums; they will be removed.')\n",
    "  notes = [note for note in primer_ns.notes if not note.is_drum]\n",
    "  del primer_ns.notes[:]\n",
    "  primer_ns.notes.extend(notes)\n",
    "\n",
    "# Set primer instrument and program.\n",
    "for note in primer_ns.notes:\n",
    "  note.instrument = 1\n",
    "  note.program = 0\n",
    "\n",
    "# Play and plot the primer.\n",
    "note_seq.play_sequence(\n",
    "    primer_ns,\n",
    "    synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
    "note_seq.plot_sequence(primer_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-O4niaxYPWyR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Generate Continuation\n",
    "#@markdown Continue a piano performance, starting with the\n",
    "#@markdown chosen priming sequence.\n",
    "\n",
    "targets = unconditional_encoders['targets'].encode_note_sequence(\n",
    "    primer_ns)\n",
    "\n",
    "# Remove the end token from the encoded primer.\n",
    "targets = targets[:-1]\n",
    "\n",
    "decode_length = max(0, 4096 - len(targets))\n",
    "if len(targets) >= 4096:\n",
    "  print('Primer has more events than maximum sequence length; nothing will be generated.')\n",
    "\n",
    "# Generate sample events.\n",
    "sample_ids = next(unconditional_samples)['outputs']\n",
    "\n",
    "# Decode to NoteSequence.\n",
    "midi_filename = decode(\n",
    "    sample_ids,\n",
    "    encoder=unconditional_encoders['targets'])\n",
    "ns = note_seq.midi_file_to_note_sequence(midi_filename)\n",
    "\n",
    "# Append continuation to primer.\n",
    "continuation_ns = note_seq.concatenate_sequences([primer_ns, ns])\n",
    "\n",
    "# Play and plot.\n",
    "note_seq.play_sequence(\n",
    "    continuation_ns,\n",
    "    synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
    "note_seq.plot_sequence(continuation_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Wwg_8SI4eIyy"
   },
   "outputs": [],
   "source": [
    "#@title Download Continuation as MIDI\n",
    "#@markdown Download performance (primer + generated continuation)\n",
    "#@markdown as MIDI (optional).\n",
    "\n",
    "note_seq.sequence_proto_to_midi_file(\n",
    "    continuation_ns, '/tmp/continuation.mid')\n",
    "files.download('/tmp/continuation.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loV8bwJ8fOR_"
   },
   "source": [
    "# Melody-Conditioned Piano Performance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "CFnUHAk1g_rc"
   },
   "outputs": [],
   "source": [
    "#@title Setup and Load Checkpoint\n",
    "#@markdown Set up generation from a melody-conditioned\n",
    "#@markdown Transformer model.\n",
    "\n",
    "model_name = 'transformer'\n",
    "hparams_set = 'transformer_tpu'\n",
    "# ckpt_path = 'gs://magentadata/models/music_transformer/checkpoints/melody_conditioned_model_16.ckpt'\n",
    "ckpt_path = './content/melody_conditioned_model_16.ckpt'\n",
    "\n",
    "class MelodyToPianoPerformanceProblem(score2perf.AbsoluteMelody2PerfProblem):\n",
    "  @property\n",
    "  def add_eos_symbol(self):\n",
    "    return True\n",
    "\n",
    "problem = MelodyToPianoPerformanceProblem()\n",
    "melody_conditioned_encoders = problem.get_feature_encoders()\n",
    "\n",
    "# Set up HParams.\n",
    "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
    "trainer_lib.add_problem_hparams(hparams, problem)\n",
    "hparams.num_hidden_layers = 16\n",
    "hparams.sampling_method = 'random'\n",
    "\n",
    "# Set up decoding HParams.\n",
    "decode_hparams = decoding.decode_hparams()\n",
    "decode_hparams.alpha = 0.0\n",
    "decode_hparams.beam_size = 1\n",
    "\n",
    "# Create Estimator.\n",
    "run_config = trainer_lib.create_run_config(hparams)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    model_name, hparams, run_config,\n",
    "    decode_hparams=decode_hparams)\n",
    "\n",
    "# These values will be changed by the following cell.\n",
    "inputs = []\n",
    "decode_length = 0\n",
    "\n",
    "# Create input generator.\n",
    "def input_generator():\n",
    "  global inputs\n",
    "  while True:\n",
    "    yield {\n",
    "        'inputs': np.array([[inputs]], dtype=np.int32),\n",
    "        'targets': np.zeros([1, 0], dtype=np.int32),\n",
    "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
    "    }\n",
    "\n",
    "# Start the Estimator, loading from the specified checkpoint.\n",
    "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
    "melody_conditioned_samples = estimator.predict(\n",
    "    input_fn, checkpoint_path=ckpt_path)\n",
    "\n",
    "# \"Burn\" one.\n",
    "_ = next(melody_conditioned_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xqWN4dEDLVdQ"
   },
   "outputs": [],
   "source": [
    "#@title Choose Melody\n",
    "#@markdown Here you can choose a melody to be accompanied by the\n",
    "#@markdown model.  We have provided a few, or you can upload a\n",
    "#@markdown MIDI file; if your MIDI file is polyphonic, the notes\n",
    "#@markdown with highest pitch will be used as the melody.\n",
    "\n",
    "# Tokens to insert between melody events.\n",
    "event_padding = 2 * [note_seq.MELODY_NO_EVENT]\n",
    "\n",
    "melodies = {\n",
    "    'Mary Had a Little Lamb': [\n",
    "        64, 62, 60, 62, 64, 64, 64, note_seq.MELODY_NO_EVENT,\n",
    "        62, 62, 62, note_seq.MELODY_NO_EVENT,\n",
    "        64, 67, 67, note_seq.MELODY_NO_EVENT,\n",
    "        64, 62, 60, 62, 64, 64, 64, 64,\n",
    "        62, 62, 64, 62, 60, note_seq.MELODY_NO_EVENT,\n",
    "        note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT\n",
    "    ],\n",
    "    'Row Row Row Your Boat': [\n",
    "        60, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        60, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        60, note_seq.MELODY_NO_EVENT, 62,\n",
    "        64, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        64, note_seq.MELODY_NO_EVENT, 62,\n",
    "        64, note_seq.MELODY_NO_EVENT, 65,\n",
    "        67, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        72, 72, 72, 67, 67, 67, 64, 64, 64, 60, 60, 60,\n",
    "        67, note_seq.MELODY_NO_EVENT, 65,\n",
    "        64, note_seq.MELODY_NO_EVENT, 62,\n",
    "        60, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT,\n",
    "        note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT, note_seq.MELODY_NO_EVENT\n",
    "    ],\n",
    "    'Twinkle Twinkle Little Star': [\n",
    "        60, 60, 67, 67, 69, 69, 67, note_seq.MELODY_NO_EVENT,\n",
    "        65, 65, 64, 64, 62, 62, 60, note_seq.MELODY_NO_EVENT,\n",
    "        67, 67, 65, 65, 64, 64, 62, note_seq.MELODY_NO_EVENT,\n",
    "        67, 67, 65, 65, 64, 64, 62, note_seq.MELODY_NO_EVENT,\n",
    "        60, 60, 67, 67, 69, 69, 67, note_seq.MELODY_NO_EVENT,\n",
    "        65, 65, 64, 64, 62, 62, 60, note_seq.MELODY_NO_EVENT        \n",
    "    ]\n",
    "}\n",
    "\n",
    "melody = 'Twinkle Twinkle Little Star'  #@param ['Mary Had a Little Lamb', 'Row Row Row Your Boat', 'Twinkle Twinkle Little Star', 'Upload your own!']\n",
    "\n",
    "if melody == 'Upload your own!':\n",
    "  # Extract melody from user-uploaded MIDI file.\n",
    "  melody_ns = upload_midi()\n",
    "  melody_instrument = note_seq.infer_melody_for_sequence(melody_ns)\n",
    "  notes = [note for note in melody_ns.notes\n",
    "           if note.instrument == melody_instrument]\n",
    "  del melody_ns.notes[:]\n",
    "  melody_ns.notes.extend(\n",
    "      sorted(notes, key=lambda note: note.start_time))\n",
    "  for i in range(len(melody_ns.notes) - 1):\n",
    "    melody_ns.notes[i].end_time = melody_ns.notes[i + 1].start_time\n",
    "  inputs = melody_conditioned_encoders['inputs'].encode_note_sequence(\n",
    "      melody_ns)\n",
    "else:\n",
    "  # Use one of the provided melodies.\n",
    "  events = [event + 12 if event != note_seq.MELODY_NO_EVENT else event\n",
    "            for e in melodies[melody]\n",
    "            for event in [e] + event_padding]\n",
    "  inputs = melody_conditioned_encoders['inputs'].encode(\n",
    "      ' '.join(str(e) for e in events))\n",
    "  melody_ns = note_seq.Melody(events).to_sequence(qpm=150)\n",
    "\n",
    "# Play and plot the melody.\n",
    "note_seq.play_sequence(\n",
    "    melody_ns,\n",
    "    synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
    "note_seq.plot_sequence(melody_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WnAZsIYsfXWV"
   },
   "outputs": [],
   "source": [
    "#@title Generate Accompaniment for Melody\n",
    "#@markdown Generate a piano performance consisting of the chosen\n",
    "#@markdown melody plus accompaniment.\n",
    "\n",
    "# Generate sample events.\n",
    "decode_length = 4096\n",
    "sample_ids = next(melody_conditioned_samples)['outputs']\n",
    "\n",
    "# Decode to NoteSequence.\n",
    "midi_filename = decode(\n",
    "    sample_ids,\n",
    "    encoder=melody_conditioned_encoders['targets'])\n",
    "accompaniment_ns = note_seq.midi_file_to_note_sequence(midi_filename)\n",
    "\n",
    "# Play and plot.\n",
    "note_seq.play_sequence(\n",
    "    accompaniment_ns,\n",
    "    synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
    "note_seq.plot_sequence(accompaniment_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2fFhZbhIeS2f"
   },
   "outputs": [],
   "source": [
    "#@title Download Accompaniment as MIDI\n",
    "#@markdown Download accompaniment performance as MIDI (optional).\n",
    "\n",
    "note_seq.sequence_proto_to_midi_file(\n",
    "    accompaniment_ns, '/tmp/accompaniment.mid')\n",
    "files.download('/tmp/accompaniment.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pygame.midi\n",
    "import note_seq\n",
    "from note_seq.protobuf import music_pb2\n",
    "import fluidsynth\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.midi.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.midi.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pygame.midi.get_count()):\n",
    "    print(pygame.midi.get_device_info(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.midi.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_in = pygame.midi.Input(pygame.midi.get_default_input_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = midi_in.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_notes = music_pb2.NoteSequence()\n",
    "\n",
    "capture_start = events[0][1]\n",
    "capture_end = events[-1][1]\n",
    "\n",
    "captured_notes.total_time = (capture_end - capture_start)/1000\n",
    "\n",
    "for i in range(len(events)):\n",
    "    event,timestamp = events[i]\n",
    "    event_code, pitch, velocity, _ = event\n",
    "    if 144 <= event_code < 160:\n",
    "        stop_code = event_code - 16\n",
    "        for j in range(i + 1, len(events)):\n",
    "            if events[j][0][1] == pitch and events[j][0][0] == stop_code:\n",
    "                captured_notes.notes.add(pitch = pitch, start_time = (events[i][1]-capture_start)/1000, end_time = (events[j][1] - capture_start)/1000, velocity = velocity)\n",
    "                break\n",
    "                \n",
    "captured_notes.tempos.add(qpm = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.fluidsynth(captured_notes, 44000, sf2_path=\"./content/Yamaha-C5-Salamander-JNv5.1.sf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "note_seq.plot_sequence(captured_notes)\n",
    "note_seq.play_sequence(captured_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2 = note_seq.concatenate_sequences([captured_notes, captured_notes])\n",
    "note_seq.plot_sequence(cap2)\n",
    "note_seq.play_sequence(cap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.concatenate_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in captured_notes.notes:\n",
    "    note.start_time -= 1.0\n",
    "    note.end_time -= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_notes.notes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(note.end_time for note in captured_notes.notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out = pygame.midi.Output(pygame.midi.get_default_output_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.note_on(60, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.note_off(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.write(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame.mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = note_seq.fluidsynth(captured_notes, 44000, sf2_path=\"./content/Yamaha-C5-Salamander-JNv5.1.sf2\")\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(waveform)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.note_sequence_to_midi_file(captured_notes, \"captured_notes.mid\")\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"captured_notes.mid\")\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.midi.get_default_output_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.write([[[0xc0, 0, 0], 20000], [[0x90, 60, 100], 20500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fluidsynth.Synth()\n",
    "fs.start()\n",
    "\n",
    "sfid = fs.sfload(\"/Users/jjclark/Projects/music-generation/content/Yamaha-C5-Salamander-JNv5.1.sf2\")\n",
    "fs.program_select(0, sfid, 0, 0)\n",
    "\n",
    "fs.noteon(0, 60, 30)\n",
    "fs.noteon(0, 67, 30)\n",
    "fs.noteon(0, 76, 30)\n",
    "\n",
    "time.sleep(1.0)\n",
    "\n",
    "fs.noteoff(0, 60)\n",
    "fs.noteoff(0, 67)\n",
    "fs.noteoff(0, 76)\n",
    "\n",
    "time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_notes.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.fluidsynth(captured_notes, 44000, sf2_path=\"./content/Yamaha-C5-Salamander-JNv5.1.sf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.fluidsynth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.synthesize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fluidsynth.Synth()\n",
    "fs.start()\n",
    "\n",
    "sfid = fs.sfload(\".content/Yamaha-C5-Salamander-JNv5.1.sf2\")\n",
    "fs.program_select(0, sfid, 0, 0)\n",
    "\n",
    "for i in range(len(events)):\n",
    "    if i > 0:\n",
    "        this_time = events[i][1]\n",
    "        last_time = events[i-1][1]\n",
    "        time.sleep((this_time-last_time)/1000)\n",
    "    event,timestamp = events[i]\n",
    "    event_code, pitch, velocity, _ = event\n",
    "    if 144 <= event_code < 160:\n",
    "        fs.noteon(event_code - 144, pitch, velocity)\n",
    "    if 128 <= event_code < 144:\n",
    "        fs.noteoff(event_code - 128, pitch)\n",
    "    time.sleep(0.1)\n",
    "fs.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out = pygame.midi.Output(pygame.midi.get_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.write(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs = fluidsynth.Synth()\n",
    "fs.start()\n",
    "for i in range(pygame.midi.get_count()):\n",
    "    print(pygame.midi.get_device_info(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_out.note_on(60, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.noteon(0, 60, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [[[146, 78, 44, 0], 29154],\n",
    " [[146, 80, 82, 0], 29240],\n",
    " [[130, 78, 23, 0], 29338],\n",
    " [[146, 82, 68, 0], 29345],\n",
    " [[130, 80, 44, 0], 29398],\n",
    " [[130, 82, 51, 0], 29500],\n",
    " [[146, 85, 42, 0], 29796],\n",
    " [[130, 85, 35, 0], 29908],\n",
    " [[146, 85, 65, 0], 29999],\n",
    " [[130, 85, 39, 0], 30128],\n",
    " [[146, 82, 30, 0], 30612],\n",
    " [[146, 80, 82, 0], 30706],\n",
    " [[130, 82, 30, 0], 30815],\n",
    " [[146, 78, 34, 0], 30862],\n",
    " [[130, 80, 45, 0], 30866],\n",
    " [[130, 78, 26, 0], 30979],\n",
    " [[146, 75, 73, 0], 31330],\n",
    " [[130, 75, 67, 0], 31413],\n",
    " [[146, 75, 82, 0], 31519],\n",
    " [[130, 75, 56, 0], 31612]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in reversed(captured_notes.notes):\n",
    "    if note.start_time > 2.0:\n",
    "        captured_notes.notes.remove(note)\n",
    "for note in captured_notes.notes:\n",
    "    print(note.start_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_notes.notes.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_start = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "played_start.add(captured_notes.notes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluidsynth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_midi.note_number_to_name(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq.concatenate_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generating Piano Music with Transformer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
